context("Running the HM, gathering results and calculating errors")

#==============================================================================
template <- "SPE9.TEMPLATE"
from.template.path <-  system.file("extdata", template, package = "runOPM")
from.perm.inc.path <-  system.file("extdata", "GRID", "PERMVALUES.INC",
                              package = "runOPM")
from.grdecl.path <-  system.file("extdata", "GRID", "SPE9.GRDECL",
                              package = "runOPM")
basedir <- "spe9hm"
MakeProj(deckname = from.template.path, basedir = basedir)
basedir <- file.path(getwd(), basedir)
deckdir <- file.path(basedir, "DECKS")
templatepath <- file.path(deckdir, template)
griddir <- file.path(deckdir, "GRID")
if (!dir.exists(griddir)) {dir.create(griddir)}
file.copy(from.perm.inc.path, file.path(griddir, "PERMVALUES.INC"),
          overwrite = TRUE)
file.copy(from.grdecl.path, file.path(griddir, "SPE9.GRDECL"),
          overwrite = TRUE)
# build a history file
# from.hist.path <- system.file("extdata", "SPE9_CP.DATA", package = "runOPM")
# file.copy(from.hist.path, file.path(deckdir, "HISTORY.DATA"), overwrite = TRUE)
# RunFlow("HISTORY.DATA", basedir = basedir, overwrite = NULL, wait = TRUE)
# case <- "HISTORY"
# infile <- runOPM:::.FindSummary(basedir = basedir, casename = case)
# outfile <- file.path(basedir, "OUTPUT", case, paste0(case,".csv"))
# wide_raw <- runOPM:::.GetECL(case, infile, outfile)
hist_csv_name <-  system.file("testdata", "HIST_CSV.csv", package = "runOPM")
hist_csv <- suppressMessages(readr::read_csv(hist_csv_name))
hist_csv$DATE <- format(as.Date(hist_csv$DATE, "%d-%b-%Y"), "%d-%b-%Y")
numeric_cols <- !grepl("DAYS|DATE|CASE", colnames(hist_csv), perl = TRUE)
hist_csv[,numeric_cols] <- as.data.frame(data.matrix(hist_csv[,numeric_cols]))

hist_xlsx_name <-  system.file("testdata", "HIST_XLSX.xlsx",
                               package = "runOPM")
hist_xlsx <- suppressMessages(readxl::read_excel(hist_xlsx_name))
hist_xlsx$DATE <-  format(as.Date(hist_xlsx$DATE - 1, origin = "1899-12-31"),
                          "%d-%b-%Y")
numeric_cols <- !grepl("DAYS|DATE|CASE", colnames(hist_xlsx), perl = TRUE)
hist_xlsx[,numeric_cols] <- as.data.frame(
  data.matrix(hist_xlsx[, numeric_cols]))
# all.equal(hist_csv, hist_xlsx)

long_csv <- runOPM::ImportHist(ssheetfile = hist_csv_name, basedir = basedir)
long_xlsx <- runOPM::ImportHist(ssheetfile = hist_xlsx_name, basedir = basedir)
csv_df <- long_xlsx[long_xlsx$CASENAME == "HIST_CSV", c(2:7, 9:10)]
xlsx_df <- long_xlsx[long_xlsx$CASENAME == "HIST_XLSX", c(2:7, 9:10)]
# all.equal(csv_df, xlsx_df)

#------------------------------------------------------------------------------
test_that("ImportHist works", {
  # check that each method brings in the same data
  expect_equivalent(hist_csv, hist_xlsx)
  expect_equivalent(csv_df, xlsx_df)
})
#==============================================================================
spe9vars <- ReadTemplate(from.template.path, "spe9hm")
spe9vars <- EditVar(spe9vars, pattern = "PORO", truncLow = 0.1,
                    truncHigh = 2, param1 = 0.1, param2 = 2.0,
                    basedir = basedir)
spe9vars <- EditVar(spe9vars, pattern = "PERM", truncLow = 0.1,
                    truncHigh = 1.5, param1 = 0.1, param2 = 2.0,
                    basedir = basedir)
set.seed(424242)
spe9vars <- ExpDes(spe9vars, type = "fpb", basedir = basedir)
spe9decks <- BuildDecks(spe9vars, template = templatepath,  basedir = basedir,
                        overwrite = NULL, cases = NULL)

ok <- RunFlow(spe9decks, basedir = basedir, overwrite = NULL, wait = TRUE)
if (!is.null(ok)) {print(paste0("value of RunFlow ok is ", ok))}
spe9rslts <- EclSum(basedir = basedir)
# head(spe9rslts)
#PlotEach(spe9rslts, wgnames = "FIELD")
long <- runOPM::CalcErrors(long = spe9rslts, base_case = "HIST_CSV",
                               basedir = basedir)

# psfn <- file.path(basedir, "REPORTS", "PROJSUM.csv")
# long <- readr::read_csv(psfn, col_types = runOPM:::.LongColSpec())
element_error <- ErrorByElement(long = long, basedir = basedir)
# eefn <- file.path(basedir, "REPORTS", "ElementError.csv")
# eesum <- readr::read_csv(eefn, col_types = runOPM:::.ErrorByElementColSpec())
# head(element_error)
# summary(element_error)
member_error <- ErrorByMember(long = long, basedir = basedir)
# mefn <- file.path(basedir, "REPORTS", "MemberError.csv")
# mesum <- readr::read_csv(mefn, col_types = runOPM:::.ErrorByMemberColSpec())
# head(member_error)
# summary(member_error)

#------------------------------------------------------------------------------
test_that("Error calculation and summarizing works", {
  expect_equal_to_reference(CalcErrors(spe9rslts, "HIST_CSV", basedir),
                            "test_calc_errors.rds")
  expect_equal_to_reference(ErrorByElement(long, basedir),
                            "test_element_errors.rds")
  expect_equal_to_reference(ErrorByMember(long, basedir),
                            "test_member_errors.rds")
})
#==============================================================================
# clean things up for manual testing
# rm(list = ls())
# setwd("/home/gerw/gitrepos/runOPM/tests/testthat")
# basedir <- "spe9hm"
# basedir <- file.path(getwd(), basedir)
# deckdir <- file.path(basedir, "DECKS")
# varfn <- file.path(deckdir, "SPE9.rds")
# spe9vars <- readRDS(varfn)
# psfn <- file.path(basedir, "REPORTS", "PROJSUM.csv")
# long <- readr::read_csv(psfn, col_types = runOPM:::.LongColSpec())
# mefn <- file.path(basedir, "REPORTS", "MemberError.csv")
# mesum <- readr::read_csv(mefn, col_types = runOPM:::.ErrorByMemberColSpec())
# PlotEach(long, wgnames = "FIELD")

# run all of the models
rm(list = ls())
setwd("/home/gerw/gitrepos/runOPM/tests/testthat")
basedir <- "spe9hm"
basedir <- file.path(getwd(), basedir)
deckdir <- file.path(basedir, "DECKS")
template <- "SPE9.TEMPLATE"
templatepath <- file.path(deckdir, template)
varfn <- file.path(deckdir, "SPE9.rds")
spe9vars <- readRDS(varfn)
spe9decks <- runOPM::BuildDecks(spe9vars, template = templatepath,  basedir = basedir,
                        overwrite = NULL, cases = NULL)
# ok <- RunFlow(spe9decks, basedir = basedir, overwrite = NULL, wait = TRUE)
# if (!is.null(ok)) {print(paste0("value of RunFlow ok is ", ok))}

# spe9rslts <- runOPM::EclSum(basedir = basedir)
# spe9rslts <- runOPM::CalcErrors(long = spe9rslts, base_case = "HIST_CSV",
#                            basedir = basedir)
psfn <- file.path(basedir, "REPORTS", "PROJSUM.csv")
spe9rslts <- readr::read_csv(psfn, col_types = runOPM:::.LongColSpec())
# runOPM::PlotEach(spe9rslts, wgnames = "FIELD")

# spe9_mem_err <- ErrorByMember(long = spe9rslts, basedir = basedir)
# head(spe9_mem_err)
# summary(spe9_mem_err)
mefn <- file.path(basedir, "REPORTS", "MemberError.csv")
spe9_mem_err <- readr::read_csv(mefn, col_types = runOPM:::.ErrorByMemberColSpec())

cases <- unique(spe9_mem_err[,c("CASENAME", "WGNAME", "KEYWORD")])
filt_casename <- !grepl("HIST", spe9_mem_err$CASENAME)
filt_wgname <- grepl("FIELD", spe9_mem_err$WGNAME)
filt_keyword <- grepl("WOPR|WGPR|WWPR", spe9_mem_err$KEYWORD)
filt <- filt_casename & filt_wgname & filt_keyword27
cases <- unique(spe9_mem_err[filt,c("CASENAME", "WGNAME", "KEYWORD")])
# cases
# nrow(cases)
# summary(spe9_mem_err[filt,])
#
# length(unique(spe9_mem_err[,c("CASENAME")])) # 64 if you remove the two HIST cases
# length(unique(spe9_mem_err[,c("WGNAME")])) # 27
# length(unique(spe9_mem_err[,c("KEYWORD")])) # 11
# 27 * 11 = 297; 297 * 64 = 19,008
#
# This is doing the work by hand; flexible functions need to be added to runOPM for this
des <- spe9vars$expDesignCoded
filt_casename <- !grepl("HIST", spe9_mem_err$CASENAME)
filt_field <- grepl("FIELD", spe9_mem_err$WGNAME)
filt_wopr <- grepl("WOPR", spe9_mem_err$KEYWORD)
filt_wgpr <- grepl("WGPR", spe9_mem_err$KEYWORD)
filt_wwpr <- grepl("WWPR", spe9_mem_err$KEYWORD)
filto <- filt_field & filt_wopr & filt_casename
filtg <- filt_field & filt_wgpr & filt_casename
filtw <- filt_field & filt_wwpr & filt_casename
# Need to be sure that the response vector is in the same order as the rows in
#   the design
res <- list(
  FIELD.WOPR.MEAN_FRAC_ERR = spe9_mem_err[filto, "MEAN_FRAC_ERR"],
  FIELD.WOPR.ABS_MEAN_FRAC_ERR = spe9_mem_err[filto, "ABS_MEAN_FRAC_ERR"],
  FIELD.WGPR.MEAN_FRAC_ERR = spe9_mem_err[filtg, "MEAN_FRAC_ERR"],
  FIELD.WGPR.ABS_MEAN_FRAC_ERR = spe9_mem_err[filtg, "ABS_MEAN_FRAC_ERR"],
  FIELD.WWPR.MEAN_FRAC_ERR = spe9_mem_err[filtw, "MEAN_FRAC_ERR"],
  FIELD.WWPR.ABS_MEAN_FRAC_ERR = spe9_mem_err[filtw, "ABS_MEAN_FRAC_ERR"]
)
spe9.km <- list(
  FIELD.WOPR.MEAN_FRAC_ERR.KM = DiceKriging::km(design = des, response = res[[1]]),
  FIELD.WOPR.ABS_MEAN_FRAC_ERR.KM = DiceKriging::km(design = des, response = res[[2]]),
  FIELD.WGPR.MEAN_FRAC_ERR.KM = DiceKriging::km(design = des, response = res[[3]]),
  FIELD.WGPR.ABS_MEAN_FRAC_ERR.KM = DiceKriging::km(design = des, response = res[[4]]),
  FIELD.WWPR.MEAN_FRAC_ERR.KM = DiceKriging::km(design = des, response = res[[5]]),
  FIELD.WWPR.ABS_MEAN_FRAC_ERR.KM = DiceKriging::km(design = des, response = res[[6]])
)
kriging.mean <- function(Xnew, m){
  DiceKriging::predict.km(m, Xnew, "UK", se.compute = FALSE, checkNames = FALSE)$mean
}
# Here ml is a list of km models and results is a matrix  with a row for each row in the
#   design (Xnew) and a column for each km model in ml.  Xnew has  acolumn for each
#   variable in the km models
kriging.mean.multi <- function(Xnew, ml){
  print(Xnew)
  nmodels <- length(ml)
  print(paste0("nmodels = ", nmodels))
  if (is.vector(Xnew)) {
    nvars <- length(Xnew)
    Xnew <- matrix(Xnew, nrow = 1, ncol = nvars)
  }
  ncases <- nrow(Xnew)
  print(paste0("ncases = ", ncases))
  results <- matrix(data = numeric(length = ncases * nmodels),
                    nrow = ncases, ncol = nmodels)
  colnames(results) <- names(ml)
  for (i in 1:nmodels) {
    results[,i] <- kriging.mean(Xnew, ml[[i]])
  }
  return(results)
}
# xnew_vector <- c(-0.253709512, 0.148784049, -0.987359760, 0.999873166, -0.998757360, 1.000000000, 0.992461895, 0.121990765, 0.303445039, 0.159005818, 0.990299825, 0.204836388,-0.271634015, -0.222063362, -0.099208982, -0.020641466, -0.391249108, -0.155418668, -0.068844850, -0.052152262, -0.997624071, 0.007700958, -0.009354477, -0.148923014, -0.089259576, 0.035052698, -0.170242952, 0.232523847, -0.173592743, 0.068541725)
# spe9.km.test.vector <- kriging.mean.multi(Xnew = xnew_vector, ml = spe9.km)
# spe9.km.test <- kriging.mean.multi(Xnew = des, ml = spe9.km)

# Plackett-Burman appears to be a poor choice when trying to assess which
#   variables are important.
# If one creates Sobol indices for a number of objectives, a numerical method needs to
#   be available to compare the cases, and determin which input variables matter.
# A ggplot method needs to be made for fast99, as well as a heatmap for multiple fast99
#
# Need to look at multisensi, an R package that deals with multi-objective sensitivities
fact <- colnames(des)
spe9.sobol <- list(
  Oil.mean.err <- sensitivity::fast99(model = kriging.mean, factors = fact,
                                      n = 1000,
                                      q = "qunif", q.arg = list(min = -1, max = 1),
                                      m = spe9.km[[1]]),
  Oil.abs.mean.err <- sensitivity::fast99(model = kriging.mean, factors = fact,
                                          n = 1000,
                                          q = "qunif", q.arg = list(min = -1, max = 1),
                                          m = spe9.km[[2]]),
  Gas.mean.err <- sensitivity::fast99(model = kriging.mean, factors = fact,
                                      n = 1000,
                                      q = "qunif", q.arg = list(min = -1, max = 1),
                                      m = spe9.km[[3]]),
  Gas.abs.mean.err <- sensitivity::fast99(model = kriging.mean, factors = fact,
                                          n = 1000,
                                          q = "qunif", q.arg = list(min = -1, max = 1),
                                          m = spe9.km[[4]]),
  Water.mean.err <- sensitivity::fast99(model = kriging.mean, factors = fact,
                                      n = 1000,
                                      q = "qunif", q.arg = list(min = -1, max = 1),
                                      m = spe9.km[[5]]),
  Water.abs.mean.err <- sensitivity::fast99(model = kriging.mean, factors = fact,
                                          n = 1000,
                                          q = "qunif", q.arg = list(min = -1, max = 1),
                                          m = spe9.km[[6]])
)
plot(spe9.sobol[[1]])
plot(spe9.sobol[[2]])
plot(spe9.sobol[[3]])
plot(spe9.sobol[[4]])
plot(spe9.sobol[[5]])
plot(spe9.sobol[[6]])

spe9.total.sobol <- data.frame(
  Oil.mean.err       = 1 - spe9.sobol[[1]]$Dt / spe9.sobol[[1]]$V,
  Oil.abs.mean.err   = 1 - spe9.sobol[[2]]$Dt / spe9.sobol[[2]]$V,
  Gas.mean.err       = 1 - spe9.sobol[[3]]$Dt / spe9.sobol[[3]]$V,
  Gas.abs.mean.err   = 1 - spe9.sobol[[4]]$Dt / spe9.sobol[[4]]$V,
  Water.mean.err     = 1 - spe9.sobol[[5]]$Dt / spe9.sobol[[5]]$V,
  Water.abs.mean.err = 1 - spe9.sobol[[6]]$Dt / spe9.sobol[[6]]$V
)
rownames(spe9.total.sobol) <- fact
spe9.total.sobol

# now, what about pareto?
SMS_opt <- crit_optimizer(model = spe9.km, lower = rep(-1,30),
                          upper = rep(1,30))
# library(parallel)
# no_cores <- detectCores() - 2
# cl <- makeCluster(no_cores)
# # I haven't succeeded yet in getting it to use the parallel cluster or GParetoptim
# # max = FALSE means we are minimizing the errors
ml <- spe9.km
nvars <- ml[[1]]@d
ncases <- length(ml)
maxval <- -10^.Machine$double.min.exp
minval <- 10^.Machine$double.min.exp
for (i in 1:ncases) {
  maxval <- max(ml[[i]]@X, maxval)
  minval <- min(ml[[i]]@X, minval)
}
opt_gen <- c(method = "genoud", fn = kriging.mean, nvars = nvars, max = FALSE,
             hard.generation.limit = FALSE)#,
#             cluster = cl)
opt_pso <- c(method = "pso", fn = kriging.mean, maxit = 20) # doesn't work, yet
spe9.opt <- GParetoptim(model = ml, fn = kriging.mean.multi, nsteps = 20,
                        lower = rep(minval, nvars), upper = rep(maxval, nvars),
                        optimcontrol = opt_gen, ml = ml)
saveRDS(spe9.opt, file = "spe9_opt.rds")
# stopCluster(cl)
plotGPareto(spe9.opt)




# xnew <- runif(30, min = -1, max = 1)
# kriging.mean.multi(t(xnew), spe9.km)
#
# res <- easyGParetoptim(fn = DTLZ2, budget = 50, lower = rep(0, 4),
#                        upper = rep(1, 4), control = list(maxit = 40))
# plotGPareto(res, UQ_PS = TRUE, control = list(lower = rep(0, 4),
#                                               upper = rep(1, 4), option = "mean",
#                                               resolution = 25, nintegpoints = 100))
#
# test.out <- DTLZ2(res$par)

#------------------------------------------------------------------------------
test_that("VarSens1 works", {
  expect_equal(1, 1)
})
#==============================================================================
#------------------------------------------------------------------------------
test_that("VarSens2 works", {
  expect_equal(1, 1)
})

#==============================================================================
# clean up
# unlink("spe9hm", recursive = TRUE)
